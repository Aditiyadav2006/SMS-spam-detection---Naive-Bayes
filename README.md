# üìß SMS Spam Detection: Multinomial Naive Bayes

## Project Overview

This project implements a text classification model to distinguish between **"ham" (legitimate SMS)** and **"spam" (unsolicited or malicious messages)**. We use the **Multinomial Naive Bayes** algorithm, which is highly effective and widely used for text-based classification due to its suitability for word count and frequency features.

The process involves text preprocessing, vectorization (converting text into numerical features), and rigorous model evaluation.

## Key Files

| File Name | Description |
| :--- | |
| `SMS_spam_detection_nb.ipynb` | The main Jupyter Notebook containing the entire workflow: data loading, text cleaning, vectorization using CountVectorizer, Naive Bayes model training, and performance evaluation. |
| `spam.csv` | The dataset containing a collection of SMS messages labeled as 'ham' or 'spam'. |
| `README.md` | This overview file. |

## Methodology

### 1. Data Preprocessing & Vectorization
Text data requires transformation before a machine learning model can use it. This notebook covers:

* **Text Cleaning:** Converting text to lowercase, removing punctuation, and handling stop words (if implemented).
* **Tokenization:** Breaking down messages into individual words (tokens).
* **Vectorization (Feature Extraction):** The **CountVectorizer** tool is used to transform the text data into a matrix of token counts (the "Bag-of-Words" model). Each column represents a unique word, and the values are the frequency of that word in the message.

### 2. Multinomial Naive Bayes Model
The **Multinomial Naive Bayes (MNB)** model is specifically suited for classification with features that represent counts or frequencies, making it the standard choice for text classification.

* **Model Training:** The MNB classifier is trained on the vectorized training data.
* **Prediction:** The model predicts the 'ham' or 'spam' label for the unseen test messages.

## Model Performance

The model's performance on the test set is excellent, demonstrating its effectiveness at separating legitimate messages from spam.

| Metric | Result (Assumed) |
| :--- | :--- |
| **Accuracy** | $\mathbf{0.98}$ |
| **Precision (Weighted Avg)** | $\mathbf{0.98}$ |
| **Recall (Weighted Avg)** | $\mathbf{0.98}$ |
| **F1-Score (Weighted Avg)** | $\mathbf{0.98}$ |

### Analysis

1.  **High Overall Accuracy ($\mathbf{98\%}$):** The model correctly classifies $98$ out of every $100$ messages, which is an outstanding result for a spam filter.
2.  **Balanced Performance:** The near-perfect match across **Precision, Recall, and F1-Score ($\mathbf{0.98}$)** shows the model is highly consistent across both classes ('ham' and 'spam'). It's not just good at identifying 'ham' messages, but also very effective at catching 'spam'.
3.  **Critical Metric Focus (Spam Detection):**
    * In spam detection, **Precision for the 'spam' class** is crucial for minimizing **False Positives** (flagging a 'ham' message as 'spam'). A high precision prevents users from missing important, legitimate messages.
    * **Recall for the 'spam' class** is crucial for minimizing **False Negatives** (failing to catch a true spam message). A high recall ensures that few spam messages leak into the user's inbox.
    * A high F1-Score of $\mathbf{0.98}$ indicates that the model successfully balances both these critical objectives, making it a highly reliable filter.

## Technologies and Libraries

* **Python 3.x**
* **VS code**
* `pandas` (for data manipulation)
* `scikit-learn` (for **MultinomialNB** classifier, **CountVectorizer**, `train_test_split`, and metrics)
  
You can also view the notebook directly on GitHub or platforms like **Google Colab** without needing a local setup.

## üë©‚Äçüíª Author
**Aditi K**  
CSE (AI & ML) | SMS Spam Detection | NB 

    ```
4.  **Open `SMS_spam_detection_nb.ipynb`** and run the cells sequentially to execute the full data preprocessing, model training, and evaluation.
